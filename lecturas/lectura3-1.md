# Comentario lectura 3-1

### Performance of Recommender Algorithms on Top-N Recommendation Tasks

En la lectura se presenta un enfoque algoritmo basado en métricas de accuracy, proponiendo un cambio al estándar actual, el cual se basa en la minimización de error. Dentro de esto, el autor propone los cambios necesarios para establecer métodos que usen estas métricas basados en lo que existe actualmente (kNN y SVD), donde finalmente se nos presenta un método principal llamado PureSVD. Finalmente se realizan experimentos prácticos de los métodos, tanto como no personalizados, basados en error y basados en métricas de precisión; donde el método propuesto alcanza un rendimiento mayor en todos los casos validando el enfoque presentado por el autor.

Dentro del punto central del texto es interesante como se aborda el uso de métricas para medir el rendimiento los sistemas recomendables usados actualmente, donde se nos dice y es sabido se usa el error generado en la predicción respecto a los datos reales para medirlo, pero realmente esta se basa en números con los cuales el usuario no tiene contacto realmente, lo cual pierde un poco de validez para que nuestro objetivo mejorar la experiencia de usuario con la predicción. Para este aspecto se vuelve interesante o más lógico el uso de métricas de precisión que se basen en evaluar un qué tan buena es la recomendación cómo tal sin dar tanta relevancia a números. Lo anterior provoca que como lector se dispone de un nuevo punto de vista con el cual enfocar los trabajos que se puedan realizar o la evaluación de algunos existentes.

Una acotación interesante que no se suele dar en trabajos de este tipo es darle un significado al comportamiento de los factores latentes de los método basados en SVD, en este caso el autor nos presenta que dado los resultados se puede decir que cuando se quiere predecir objeto más populares basta con pocos factores, ya que se tiene más información sobre ellos, pero en el caso del uso de los datos sin los elementos populares se necesita tener mucho más características para traer su información y así generar la recomendación. Poder darle significado a la cantidad de factores latentes usados da una noción al lector que permite entender mejor el trabajo con este método que suele ser bastante abstracto, y puede llamar a buscar algún tipo de patrón en los que ya existe o trabajo futuro sobre SVD.

Otro punto interesante que nos propone el texto es el uso el set de testing quitando los elementos más populares o que se tiene más información de ellos, los cuales son la cabeza de distribución long tail, de tal forma que la tarea de recomendación es más desafiante y muestra de mejor manera el poder de predicción de los algoritmos, ya que este es el desafío real para este tipo de trabajos qué es la predicción personalizada con baja densidad de información, y es lo que los diferencia de métodos no personalizados que ocupan como gran baza ese grupo de objetos. Lo anterior añade una nueva prueba que parece necesaria para evaluar de mejor manera un método personalizado a la hora de proponerlo, y que normalmente no se ve abordado.

Otro punto interesante mencionado en la lectura es cómo las métricas de error tienen un desempeño sensible cuando se trabaja con los ítems menos populares como se mencionó anteriormente, ya que éstos son muy dependientes de información disponible en el set de datos lo que provoca, que dada la distribución long tail al quitar la pequeña porción de datos populares la falta de datos genera un gran efecto negativo en estas métricas. Lo anterior nos dice que no debemos confiar demasiado en estas métricas al realizar los trabajos, ya que lo que se busca es ser efectivo en este tipo de predicciones en estos métodos, y por lo tanto es necesario al menos una validación con métricas de precisión para que nuestro algoritmo sea más útil en la práctica.

Un punto específico del algoritmo final presentado que es interesante es que se pase la descomposición matricial a una que depende solo de los ítems, lo anterior simplifica el trabajo y finalmente genera un algoritmo simple sin sacrificar rendimiento en la práctica según lo mostrado. Esto nos sugiere como lectores que la realización de estas simplificaciones en nuestros trabajos son una opción que generan algoritmos menos teóricos y más aplicables a la realidad (dada escalabilidad), y que si se hacen de la manera correcta no presentan pérdida de rendimiento.

El trabajo presentado por el autor es muy relevante e interesante para nuestra área de estudio, dado que nos presenta un cambio completo de enfoque para los algoritmos generados, ya que dejamos de enfocarnos en minimizar el error y cambiamos esto por maximizar métricas de precisión en nuestras recomendaciones. Lo cual parece tener más sentido dado que el enfoque de nuestros resultados es la usabilidad para el usuario. Si bien dado todo el trabajo existente con el enfoque normal no debe ser descartado dado su valor, esto nos genera algo que a mi parecer debe ser parte del trabajo futura, que si bien no reemplace si sea considerado para la medición del rendimiento.
